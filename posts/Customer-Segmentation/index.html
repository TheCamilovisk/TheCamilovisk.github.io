<!DOCTYPE html><html lang="en" mode="dark" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Customer Segmentation in Python | Camilo Gonçalves</title><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Customer Segmentation in Python" /><meta name="author" content="Camilo Gonçalves" /><meta property="og:locale" content="en_US" /><meta name="description" content="In my last post we hade a brief discussion about Recommender Systems, one of the most widespread application of machine learning technology in industry. In this post we’ll talk about Customer Segmentation, another essential machine learning task used by companies to get insights about their clients base, like their needs, which groups should marketing programs be focused on, what preferences these groups have, how to engage new clients and so on." /><meta property="og:description" content="In my last post we hade a brief discussion about Recommender Systems, one of the most widespread application of machine learning technology in industry. In this post we’ll talk about Customer Segmentation, another essential machine learning task used by companies to get insights about their clients base, like their needs, which groups should marketing programs be focused on, what preferences these groups have, how to engage new clients and so on." /><link rel="canonical" href="https://thecamilovisk.github.io//posts/Customer-Segmentation/" /><meta property="og:url" content="https://thecamilovisk.github.io//posts/Customer-Segmentation/" /><meta property="og:site_name" content="Camilo Gonçalves" /><meta property="og:image" content="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/CustomerSegmentation.jpg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-02-04T19:38:00-03:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/CustomerSegmentation.jpg" /><meta property="twitter:title" content="Customer Segmentation in Python" /><meta name="twitter:site" content="@camilolgon" /><meta name="twitter:creator" content="@Camilo Gonçalves" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"mainEntityOfPage":{"@type":"WebPage","@id":"https://thecamilovisk.github.io//posts/Customer-Segmentation/"},"description":"In my last post we hade a brief discussion about Recommender Systems, one of the most widespread application of machine learning technology in industry. In this post we’ll talk about Customer Segmentation, another essential machine learning task used by companies to get insights about their clients base, like their needs, which groups should marketing programs be focused on, what preferences these groups have, how to engage new clients and so on.","@type":"BlogPosting","url":"https://thecamilovisk.github.io//posts/Customer-Segmentation/","headline":"Customer Segmentation in Python","dateModified":"2021-02-04T19:38:00-03:00","datePublished":"2021-02-04T19:38:00-03:00","image":"https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/CustomerSegmentation.jpg","author":{"@type":"Person","name":"Camilo Gonçalves"},"@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Camilo Gonçalves</a></div><div class="site-subtitle font-italic">Data Scientist and Computer Vision Researcher.</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/TheCamilovisk" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/camilo-assis-a9712669/" target="_blank"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:window.open('mailto:' + ['camilolgon','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Customer Segmentation in Python</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Customer Segmentation in Python</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Feb 4, 2021, 7:38 PM -0300" > Feb 4 <i class="unloaded">2021-02-04T19:38:00-03:00</i> </span> by <span class="author"> Camilo Gonçalves </span></div><div> Updated <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Thu, Feb 4, 2021, 4:52 PM -0600" > Feb 4 <i class="unloaded">2021-02-04T19:52:34-03:00</i> </span></div></div><div class="post-content"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/CustomerSegmentation.jpg" class="post-preview-img"><p>In my last <a href="https://thecamilovisk.github.io/posts/Collaborative-Filtering-Recommender-System/">post</a> we hade a brief discussion about Recommender Systems, one of the most widespread application of machine learning technology in industry. In this post we’ll talk about Customer Segmentation, another essential machine learning task used by companies to get insights about their clients base, like their needs, which groups should marketing programs be focused on, what preferences these groups have, how to engage new clients and so on.</p><h1 id="required-packages">Required packages</h1><ul><li>Numpy</li><li>Pandas</li><li>Scikit-Learn</li><li>Matplotlib</li><li>Seaborn</li><li>Kaggle API (optional)</li></ul><h1 id="what-is-customer-segmentation-and-why-to-use-it">What is Customer Segmentation and why to use it?</h1><p>Customer Segmentation is the process of dividing customers into groups based on common characteristics. A company might segment customers according to a wide range of factors: age, gender, marital status, purchase history, location (urban, suburban, rural), etc. Segmentation allows marketers to better tailor their marketing efforts to various audience subsets. Those efforts can relate to both communications and product development. Specifically, segmentation helps a company:</p><ul><li>Create and communicate targeted marketing messages that will resonate with specific groups of customers, but not with others (who will receive messages tailored to their needs and interests, instead).</li><li>Select the best communication channel for the segment, which might be email, social media posts, radio advertising, or another approach, depending on the segment.</li><li>Identify ways to improve products or new product or service opportunities.</li><li>Establish better customer relationships.</li><li>Test pricing options.</li><li>Focus on the most profitable customers.</li><li>Improve customer cross-sell other products and servicecs.</li></ul><p>Companies employing customer segmentation operate under the fact that every customer is different and that their marketing efforts would be better served if they target specific, smaller groups with messages that those consumers would find relevant and lead them to buy something. Companies also hope to gain a deeper understanding of their customer’s preferences and needs with the idea of discovering what each segment finds most valuable to more accurately tailor marketing materials toward that segment.</p><h1 id="dataset-description">Dataset Description</h1><p>For this project we’ll use the <a href="https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python">Mall Custumer Segmentation Data</a>, a dataset created with the sole purpose of learning the concepts of Customer Segmentation using Machine Learning.</p><p>The data is composed by the following variables:</p><ul><li><strong>CustomerID</strong>: Unique ID assigned to the customer</li><li><strong>Gender</strong>: Gender of the customer</li><li><strong>Age</strong>: Age of the customer</li><li><strong>Annual Income (R$)</strong>: Annual Income of the customer</li><li><strong>Spending score (1-100)</strong>: Score assigned by the mall based on the customer behavior and spending nature.</li></ul><h1 id="exploratory-data-analysis">Exploratory Data Analysis</h1><p>Let’s begin by downloading our data. Here I’ll use the <a href="https://github.com/Kaggle/kaggle-api">kaggle API</a> package, but you are free to donwload it manually or by other means.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"default"</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c1"># !kaggle datasets download -d vjchoudhary7/customer-segmentation-tutorial-in-python
# !unzip customer-segmentation-tutorial-in-python.zip
# !rm customer-segmentation-tutorial-in-python.zip
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">customer_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"Mall_Customers.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s">"CustomerID"</span><span class="p">)</span>
<span class="n">customer_data</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 200 entries, 1 to 200
Data columns (total 4 columns):
 #   Column                  Non-Null Count  Dtype 
---  ------                  --------------  ----- 
 0   Gender                  200 non-null    object
 1   Age                     200 non-null    int64 
 2   Annual Income (k$)      200 non-null    int64 
 3   Spending Score (1-100)  200 non-null    int64 
dtypes: int64(3), object(1)
memory usage: 7.8+ KB
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">customer_data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Gender<th>Age<th>Annual Income (k$)<th>Spending Score (1-100)<tr><th>CustomerID<th><th><th><th><tbody><tr><th>1<td>Male<td>19<td>15<td>39<tr><th>2<td>Male<td>21<td>15<td>81<tr><th>3<td>Female<td>20<td>16<td>6<tr><th>4<td>Female<td>23<td>16<td>77<tr><th>5<td>Female<td>31<td>17<td>40</table></div><p>As we can see, the data is comprised by 200 entries.</p><p>Let’s check for missing values</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">missing_info</span> <span class="o">=</span> <span class="n">customer_data</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">().</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">missing_info</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">"NA count"</span><span class="p">]</span>
<span class="n">missing_info</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>NA count<tbody><tr><th>Gender<td>0<tr><th>Age<td>0<tr><th>Annual Income (k$)<td>0<tr><th>Spending Score (1-100)<td>0</table></div><p>We don’t have missing data. Good! For such a small dataset, missing values would be a problem.</p><p>Let’s check some dataset statics</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="s">"Numeric variables:"</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">customer_data</span><span class="p">.</span><span class="n">describe</span><span class="p">().</span><span class="n">T</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"-"</span> <span class="o">*</span> <span class="mi">87</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Nominal variables:"</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">customer_data</span><span class="p">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">"O"</span><span class="p">).</span><span class="n">T</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Numeric variables:
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>count<th>mean<th>std<th>min<th>25%<th>50%<th>75%<th>max<tbody><tr><th>Age<td>200.0<td>38.85<td>13.969007<td>18.0<td>28.75<td>36.0<td>49.0<td>70.0<tr><th>Annual Income (k$)<td>200.0<td>60.56<td>26.264721<td>15.0<td>41.50<td>61.5<td>78.0<td>137.0<tr><th>Spending Score (1-100)<td>200.0<td>50.20<td>25.823522<td>1.0<td>34.75<td>50.0<td>73.0<td>99.0</table></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>---------------------------------------------------------------------------------------
Nominal variables:
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>count<th>unique<th>top<th>freq<tbody><tr><th>Gender<td>200<td>2<td>Female<td>112</table></div><p>As we can see, <strong>Gender</strong> is a nominal variable, while <strong>Age</strong>, <strong>Annual Income (k\$)</strong> and <strong>Spending Score (1-100)</strong> are numeric continuous variables. We can also note that <strong>Gender</strong> is also a binary variable.</p><h2 id="gender-distribution">Gender Distribution</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Gender"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">customer_data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Using count plot to display Gender Comparision"</span><span class="p">)</span>

<span class="n">customer_data</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"Gender"</span><span class="p">).</span><span class="n">size</span><span class="p">().</span><span class="n">plot</span><span class="p">.</span><span class="n">pie</span><span class="p">(</span><span class="n">autopct</span><span class="o">=</span><span class="s">"%.1f%%"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Ratio of female and male"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">""</span><span class="p">);</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_14_0.png" alt="png" /></p><p>As said before, the “Gender” variable is a <strong>binary</strong> variable, and it’s value can be either <strong>Male</strong> of <strong>Female</strong>. One can also note that there are sightly more <strong>Female</strong> entries than <strong>Male</strong>.</p><h2 id="distribution-plots">Distribution plots</h2><p>The following variables are of continuous type, and we’ll basically describe then using their histogram, density estimation functions and <a href="https://blog.bioturing.com/2018/05/16/5-reasons-you-should-use-a-violin-graph/">violin plots</a>. We’ll create a function that encapsulates the creation of those plots.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">distribution_plots</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Seaborn's histplot can combine a histogram and a density estimation function
</span>    <span class="c1"># in one single plot.
</span>    <span class="n">sns</span><span class="p">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">column</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"Distribution of </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s"> feature"</span><span class="p">)</span>
    
    <span class="n">sns</span><span class="p">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">column</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"Boxplot for Descriptive Analysis of </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s"> feature"</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></table></code></div></div><h3 id="age-distribution">Age Distribution</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">distribution_plots</span><span class="p">(</span><span class="n">customer_data</span><span class="p">,</span> <span class="s">"Age"</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"blue"</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_19_0.png" alt="png" /></p><p>As we can see, 50% of the customers have between 28 and 49 years old, and the age average is about 36 years. The younger customer and the older customer have 18 and 70 years old, respectively.</p><h2 id="annual-icome-of-the-customers">Annual Icome of the Customers</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">distribution_plots</span><span class="p">(</span><span class="n">customer_data</span><span class="p">,</span> <span class="s">"Annual Income (k$)"</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#660033"</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_22_0.png" alt="png" /></p><p>From the descriptive analysis above, we can conclude that 50% of the consumers have annual income between 41,5 K\$ and 78 K\$, and the average income is about 61,5 k\$. The minimum user income is of 15 k\$ and the maximun is of 137 k\$.</p><h2 id="spending-score-of-the-customers">Spending Score of the Customers</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">distribution_plots</span><span class="p">(</span><span class="n">customer_data</span><span class="p">,</span> <span class="s">"Spending Score (1-100)"</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#6600cc"</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_25_0.png" alt="png" /></p><p>50% of the customers have the score between 35 and 73, with the mean score of approximately 50.</p><h1 id="customer-base-clustering">Customer Base Clustering</h1><p>Gennearally speaking, customer segmentation requires a company to gather specific information/data about customers, analyze it and identify patterns that can be used to create the segments. Typical information-gathering methods include:</p><ul><li>Face-to-face or telephone interviews</li><li>Surveys</li><li>General research using published information about market categories</li><li>Focus groups</li></ul><p>The gathered data then is analyzed by marketing specialists with the aid of other professionals, like designers, entreperneurs and, of course, data scientists and machine learning practioneers. In this post we’ll ignore all complex segmentation stages of a marketing company and focus on an simple machine learning approach using the <strong>k-means clustering algorithm</strong>.</p><h2 id="k-means-algorithm">K-means Algorithm</h2><p>The most common k-means clustering algorithm (a.k.a naïve k-means) is a <strong>unsupervised learning</strong> technique that consists in iterativelly cluster similar data based on the <strong>Euclidian Distance</strong> of each data point, or observations, to its closest cluster centroid. The algorithm aims to minimize the distances between cluster centroids and their assigned observations and maximize inter-cluster distances.</p><p>We can summarize the k-means algorithm as:</p><ol><li>The number \(k\) of clusters to be created is chosen.</li><li>The algorithm randomly choose \(k\) observations as initial cluster centroids.</li><li>The Euclidian Distances between all observations and the cluster centroids are computed.</li><li>Each observation is assigned to its closest cluster.</li><li>Each cluster centroids are updated with the mean point of all cluster observations.</li><li>Repeat steps <strong>3</strong> to <strong>5</strong> until convergency (i.e: maximun number of iterations, sum of squared observation-cluster distances, etc.)</li></ol><p>These steps are executed a bunch of times for different initial centroids. The execution that results in <em>minimum difference of variation between clusters</em> is chosen as the best one.</p><p>The k-means algorithm clusters data by trying to separate samples in \(k\) groups of equal variance, minimizing a criterion know as the <strong>inertia</strong> or <strong>intra-cluster sum-of-squares</strong>, which is mathematically defined as:</p>\[\textbf{inertia} = \sum_{i=0}^k \min_{\mu_j \in C} (||x_i - \mu_j||^2)\]<p>where \(x_i\) is the components vector of the \(i\)-th observation and \(\mu_j\) is the centroid of the \(j\)-th cluster. Inertia can be recognized as a measure of how internally coherent clusters are.</p><h2 id="determining-the-optimal-number-of-clusters">Determining the Optimal Number of Clusters</h2><p>Now that we know the basics of k-means clustering, there is one question left: how do we choose the number \(k\) of clusters?</p><p>Depending of the problem statement we could set \(k\) to an arbitrary value. For a set of cloth items we could, for example, cluster them into 3 groups by their sizes: Big, Medium and Small.</p><p>In cases where the value of \(k\) was not made clear by the business logic, one can use a value search method. In this post we’ll present two of the most popular:</p><ul><li>Elbow method</li><li>Silhouette method</li></ul><h3 id="elbow-method">Elbow Method</h3><p>The elbow method consists in plotting the <strong>inertia</strong> of clusterings for several values of \(k\).</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="k">def</span> <span class="nf">get_clustering_inertia</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s">"full"</span><span class="p">,</span>  <span class="c1"># we'll use the classical EM-style algorithm. Refer to sklearn's user guide: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
</span>        <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>  <span class="c1"># use this to get reproducible results
</span>    <span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span>
</pre></table></code></div></div><p>To be used by the k-means algorithm, all variables must be of <strong>numeric</strong> type. As <strong>Gender</strong> contains only two values, we’ll replace all “Male” occurences by 0 and “Female” occurrences by 1.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">customer_data</span><span class="p">[</span><span class="s">"Gender"</span><span class="p">].</span><span class="n">replace</span><span class="p">({</span><span class="s">"Male"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"Female"</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><p>Now we can proceed with our analysis.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">inertia_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_clustering_inertia</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">customer_data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)]</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">inertia_values</span><span class="p">,</span> <span class="s">"o-"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Inertia values for diferent values of $ k $"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Number of clusters $ k $"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Inertia"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_36_0.png" alt="png" /></p><p>We’ll choose the value of \(k\) clusters which if we add another cluster it doesn’t result in a relevant improvement. In our case, the value of <strong>6</strong> clusters satisfy this condition.</p><h3 id="average-solhouette-method">Average Solhouette Method</h3><p>The Silhouette method provides a succint graphical representation of how well each observation has been classified.</p><p>The silhouette coefficient <strong>s</strong> is defined as:</p>\[\textbf{s} = \frac{b - a}{max(a, b)}\]<p>where \(a\) is the means distance between a sample and all other observations in the same class, and \(b\) is the mean distance between a sample and all other observations in the next nearest cluster. The silhouette coefficient is a measure of how similar an observation is to its own cluster compared to other clusters. It ranges from -1 to +1, where a high values indicates that the observation is well matched to its own cluster and poorly matched to neighboring clusters.</p><p>Our approach will be simple: we’ll compute the average silhouette coefficient of several clustering strategies using different values of \(k\). Gennerally speaking, if we obtain a high average silhouette coefficient value it means that we have good clustering.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_samples</span><span class="p">,</span> <span class="n">silhouette_score</span>
</pre></table></code></div></div><p>The sklearn’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_samples.html#">silhouette_samples</a> function computes the silhouette coefficients for for each data sample and its assigned cluster centroid. <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html">silhouette_score</a> returns the average sillhouette coefficient for a clustering given the data and it’s assigned cluster centroids.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">plot_silhouettes</span><span class="p">(</span><span class="n">c_model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">c_labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c_model</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">)</span>
    
    <span class="n">samples_coeffs</span> <span class="o">=</span> <span class="n">silhouette_samples</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">c_labels</span><span class="p">)</span>
    
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s">"Spectral"</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
    
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">()</span> <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">ax</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_clusters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span><span class="p">])</span>
    
    <span class="n">y_lower</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="n">ith_cluster_coeffs</span> <span class="o">=</span> <span class="n">samples_coeffs</span><span class="p">[</span><span class="n">c_labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">ith_cluster_coeffs</span><span class="p">.</span><span class="n">sort</span><span class="p">()</span>
        
        <span class="n">size_cluster_i</span> <span class="o">=</span> <span class="n">ith_cluster_coeffs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_lower</span> <span class="o">+</span> <span class="n">size_cluster_i</span>
        
        <span class="n">color</span> <span class="o">=</span> <span class="n">cmap</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">fill_betweenx</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_lower</span><span class="p">,</span> <span class="n">y_upper</span><span class="p">),</span>
                         <span class="mi">0</span><span class="p">,</span> <span class="n">ith_cluster_coeffs</span><span class="p">,</span>
                         <span class="n">facecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">y_lower</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">size_cluster_i</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        
        <span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_upper</span> <span class="o">+</span> <span class="mi">10</span>
    
    <span class="n">silhouette_avg</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">c_labels</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"Silhouette plot for </span><span class="si">{</span><span class="n">n_clusters</span><span class="si">}</span><span class="s"> clusters"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s">"Silhouette coefficient values (Avg = </span><span class="si">{</span><span class="n">silhouette_avg</span><span class="p">:</span><span class="mf">3.2</span><span class="n">f</span><span class="si">}</span><span class="s">)"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Cluster label"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">silhouette_avg</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"red"</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">"--"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">silhouette_avg</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="n">silhouette_avgs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s">"full"</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">customer_data</span><span class="p">)</span>
    <span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">customer_data</span><span class="p">)</span>
    
    <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">si</span> <span class="o">=</span> <span class="n">plot_silhouettes</span><span class="p">(</span><span class="n">kmeans</span><span class="p">,</span> <span class="n">customer_data</span><span class="p">,</span>
                         <span class="n">c_labels</span><span class="o">=</span><span class="n">cluster_labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">silhouette_avgs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">si</span><span class="p">)</span>

<span class="n">silhouette_avgs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">silhouette_avgs</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_0.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_1.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_2.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_3.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_4.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_5.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_6.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_7.png" alt="png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_42_8.png" alt="png" /></p><p>Now we can visualize the optimal cluster</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">silhouette_avgs</span><span class="p">,</span> <span class="s">"o-"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">silhouette_avgs</span><span class="p">.</span><span class="n">argmax</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">"--"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Optimal number of clusters"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Number of clusters ($ k $)"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Average silhouette width"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_44_0.png" alt="png" /></p><p>As we can see, the silhouette plot confirms that the optimal number of clusters is <strong>6</strong>.</p><h1 id="clustering-visualization">Clustering Visualization</h1><h2 id="visualizing-in-a-reduced-variables-space">Visualizing in a Reduced Variables Space</h2><p>As the dataset is composed of 4 variables, it is impossible for us to visulize the clustering in such space. So we need a way to visualize this data in a <strong>reduced space</strong>. For this, we’ll used the so called <a href="https://en.wikipedia.org/wiki/Principal_component_analysis"><strong>Principal Component Analysis</strong></a> (<strong>PCA</strong>), a statistical technique that decompose a multivariate dataset in a set of <strong>principal components</strong>: successive orthogonal components that explain a maximun amount of the variance. The first principal component can be defined as a direction of maximun variance of the projected data, while the second component can be defined as a direction of the second maximun variance of the projected data, the third component is the direction of the third maximun variance, and so on.</p><p>First, we compute the optimal clustering.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">optimal_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span>
    <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s">"full"</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">customer_data</span><span class="p">)</span>
<span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">optimal_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">customer_data</span><span class="p">)</span>
</pre></table></code></div></div><p>Next we fit a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">sklearn’s PCA transformer</a> and project the data to this reduced space.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># We'll use only two princiapl Components
</span><span class="n">pc_reduced</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">customer_data</span><span class="p">)</span>

<span class="n">reduced_data</span> <span class="o">=</span> <span class="n">pc_reduced</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">customer_data</span><span class="p">)</span>
<span class="n">reduced_data</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(200, 2)
</pre></table></code></div></div><p>The 4D variable space was transformed to a 2D space, which we can use to visualize the clustering results.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">cmap</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s">"Spectral"</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">reduced_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">reduced_data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                     <span class="n">hue</span><span class="o">=</span><span class="n">cluster_labels</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Segments of Mall Customers using K-means Clustering (Principal Components)"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Component 0"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Component 1"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s">"upper left"</span><span class="p">);</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_51_0.png" alt="png" /></p><p>As we can see, clusters 0, 1, 2 and 4 are well defined and clusters 3 and 5 are a bit mixed.</p><h2 id="visualizing-variables-with-high-variation">Visualizing Variables with High Variation</h2><p>Although the above plot can show clearly the effect of the clustering, we cannot actually extract an useful information from it. It would be better to see the clustering results using a subset of the original components, but how do we do it?</p><p>Let’s fit another PCA transformer, but this time we’ll compute components for the full 4D space.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c1"># When we not supply n_components, the pricipal components are computed
# for the full feature space.
</span><span class="n">pc_full</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">customer_data</span><span class="p">)</span>
</pre></table></code></div></div><p>The PCA transformer computes the components and stores them in the <code class="language-plaintext highlighter-rouge">components_</code> attribute, sorted by the amount of variation. The amounts of variation of the components are stored in the <code class="language-plaintext highlighter-rouge">explained_variance_</code> attribute.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pc_full</span><span class="p">.</span><span class="n">explained_variance_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([7.00264432e+02, 6.84331841e+02, 1.67228881e+02, 2.45498578e-01])
</pre></table></code></div></div><p>Why have we did this? The <code class="language-plaintext highlighter-rouge">explained_variance_</code> attribute now contains the amount of variation of each variable of the dataset. The amount of variation can be interpreted as a measure of <em>how much information</em> is contained in data. High variation means more information. So, now we can tell which dataset’s variables can better explain the information in data.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">com_order</span> <span class="o">=</span> <span class="n">pc_full</span><span class="p">.</span><span class="n">explained_variance_</span><span class="p">.</span><span class="n">argsort</span><span class="p">()</span>
<span class="n">var_sorted_columns</span> <span class="o">=</span> <span class="n">customer_data</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">com_order</span><span class="p">]</span>
<span class="n">var_sorted_columns</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">var_sorted_columns</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">pc_full</span><span class="p">.</span><span class="n">explained_variance_</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Feature variation amount"</span><span class="p">);</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_58_0.png" alt="png" /></p><p>As we can see, <strong>Spending Score (1-100)</strong> and <strong>Annual Income (k$)</strong> are the variables that holds most of the information in dataset. We can visualize the clustering results using only those variables.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">cmap</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s">"Spectral"</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">var_sorted_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">var_sorted_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">customer_data</span><span class="p">,</span>
                     <span class="n">hue</span><span class="o">=</span><span class="n">cluster_labels</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Segments of Mall Customers using K-means Clustering"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s">"upper left"</span><span class="p">);</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="https://raw.githubusercontent.com/TheCamilovisk/TheCamilovisk.github.io/master/assets/img/posts/CustomerSegmentation/output_60_0.png" alt="png" /></p><p>Analysing the plot, we can clearly conclude that the clustering methodology successfully isolated 4 groups:</p><ul><li><strong>Group 0</strong>: represents customers with low Spending Scores and low Annual Incomes</li><li><strong>Group 1</strong>: represents customers with high Spending Scores and low Annual Incomes</li><li><strong>Group 4</strong>: represents customers with high Spending Scores and high Annual Incomes</li><li><strong>Group 2</strong>: represents customers with low Spending Scores and high Annual Incomes</li></ul><p>Groups <strong>3</strong> and <strong>5</strong> represents customers with both medium Spending Scores and medium Annual Incomes. These groups seems to be mixed in this reduced space, but remember that we took only the two most informative features in consideration.</p><h1 id="conclusion">Conclusion</h1><p>Modern business strive by delivering higly personalized services to their customers, which would not have been possible without some form of customer categorization or segmentation. In doing so, organizations can easily struture their services and products around their customers while targeting them to drive more revenue.</p><p>In this post we presented a simple approach to Customer Segmentation using the k-means algorithm. The clustering is based on user features, like age, gender, income and purchase history. Although we used the classic clustering methodology, many other techniques, like hierarchical clustering, Fuzzy clustering or Density-based clustering could be suitable here.</p><h1 id="references">References</h1><p>Most of the methodology present in this post was adapted from Data Flair’s <a href="https://data-flair.training/blogs/data-science-projects-code/">post</a>. Thanks to Data Falir’s team for sharing their knowledge.</p><p>The notebook of this post can found <a href="https://github.com/TheCamilovisk/DSNotebooks/blob/main/CustomerSegmentation/CustomerSegmentation.ipynb">here</a>.</p><p>Other useful links:</p><ul><li>Irfan Alghani Khalid’s post on <a href="https://towardsdatascience.com/customer-segmentation-in-python-9c15acf6f945">Customer Segmentation in Python</a></li><li>GeeksforGeeks’s post on <a href="https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/">Elbow Method for optimal value of k in KMeans</a></li><li>Sklearn’s <a href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html">page</a> on Selecting the number of clusters with silhouette analysis on KMeans clustering</li><li>Sklearn’s <a href="https://scikit-learn.org/stable/modules/clustering.html">page</a> on clustering</li><li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a> by Trevor Hastie, Robert Tibshirani and Jerome Friedman</li></ul><p>Thanks for reading to the end, and stay tuned for new posts.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/customer-segmentation/'>Customer Segmentation</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/customer-segmentation/" class="post-tag no-text-decoration" >customer segmentation</a> <a href="/tags/data-science/" class="post-tag no-text-decoration" >data science</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >machine learning</a> <a href="/tags/sklearn/" class="post-tag no-text-decoration" >sklearn</a> <a href="/tags/clustering/" class="post-tag no-text-decoration" >clustering</a> <a href="/tags/kmeans/" class="post-tag no-text-decoration" >kmeans</a> <a href="/tags/elbow-method/" class="post-tag no-text-decoration" >elbow method</a> <a href="/tags/silhouette-coefficient/" class="post-tag no-text-decoration" >silhouette coefficient</a> <a href="/tags/optimal-clustering/" class="post-tag no-text-decoration" >optimal clustering</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Customer Segmentation in Python - Camilo Gonçalves&url=https://thecamilovisk.github.io//posts/Customer-Segmentation/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Customer Segmentation in Python - Camilo Gonçalves&u=https://thecamilovisk.github.io//posts/Customer-Segmentation/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Customer Segmentation in Python - Camilo Gonçalves&url=https://thecamilovisk.github.io//posts/Customer-Segmentation/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Pannel on right side (Desktop views) v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Customer-Segmentation/">Customer Segmentation in Python</a></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/data-science/">data science</a> <a class="post-tag" href="/tags/skoptim/">skoptim</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/silhouette-coefficient/">silhouette coefficient</a> <a class="post-tag" href="/tags/recommender-systems/">recommender systems</a> <a class="post-tag" href="/tags/optimal-clustering/">optimal clustering</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/kmeans/">kmeans</a> <a class="post-tag" href="/tags/elbow-method/">elbow method</a> <a class="post-tag" href="/tags/customer-segmentation/">customer segmentation</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Collaborative-Filtering-Recommender-System/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Jan 7 <i class="unloaded">2021-01-07T00:08:00-03:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Collaborative Filtering based Recommender System</h3><div class="text-muted small"><p> Recommender systems are one of the most successful and widespread application of machine learning technologies in industry. The ability to suggest products with most appealing factor to each consum...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Collaborative-Filtering-Recommender-System/" class="btn btn-outline-primary"><p>Collaborative Filtering based Recommender System</p></a> <span class="btn btn-outline-primary disabled"><p>-</p></span></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script> <!-- The Footer v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://twitter.com/camilolgon">Camilo Gonçalves</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/data-science/">data science</a> <a class="post-tag" href="/tags/skoptim/">skoptim</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/silhouette-coefficient/">silhouette coefficient</a> <a class="post-tag" href="/tags/recommender-systems/">recommender systems</a> <a class="post-tag" href="/tags/optimal-clustering/">optimal clustering</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/kmeans/">kmeans</a> <a class="post-tag" href="/tags/elbow-method/">elbow method</a> <a class="post-tag" href="/tags/customer-segmentation/">customer segmentation</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://thecamilovisk.github.io/{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
